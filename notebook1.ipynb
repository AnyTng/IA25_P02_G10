{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27b404a75b766bd",
   "metadata": {},
   "source": [
    "# Notebook 1 - Aprendizagem Supervisionada"
   ]
  },
  {
   "cell_type": "code",
   "id": "292a62df80d45632",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Instalação das dependências usadas no notebook (para execução local).\n",
    "print(\"Hello World!\")\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install mlxtend\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8d02769bcc0ba2c",
   "metadata": {},
   "source": [
    "## Importar o Dataset e preparar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267e6d5",
   "metadata": {},
   "source": [
    "### O que será carregado\n",
    "- `df_male_players`: base de jogadores masculinos (CSV EA FC)\n",
    "- `df_female_players`: base de jogadores femininos (CSV EA FC)\n",
    "- As colunas são mantidas como no dataset original; o género é adicionado manualmente na próxima etapa."
   ]
  },
  {
   "cell_type": "code",
   "id": "bc7e531584305fc6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega os datasets brutos com jogadores masculinos e femininos.\n",
    "df_male_players = pd.read_csv(\"Data/EA_FC/male_players.csv\", low_memory=False)\n",
    "df_female_players = pd.read_csv(\"Data/EA_FC/female_players.csv\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ef09f10ecba5090",
   "metadata": {},
   "source": [
    "# Adiciona a coluna de género e junta todos os jogadores num único DataFrame.\n",
    "df_male_players[\"gender\"] = \"M\"\n",
    "df_female_players[\"gender\"] = \"F\"\n",
    "\n",
    "df_players_all = pd.concat(\n",
    "    [df_male_players, df_female_players],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Filtra apenas os jogadores da edição FC 24.\n",
    "df_players_fifa24 = df_players_all[df_players_all[\"fifa_version\"] == 24].copy()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be9844b6",
   "metadata": {},
   "source": [
    "### Estrutura do dataset unificado\n",
    "- `df_players_all`: concatenação de todos os jogadores com a coluna `gender` preenchida.\n",
    "- `df_players_fifa24`: filtro para a versão `fifa_version == 24`, criando uma cópia para evitar avisos de `SettingWithCopy`.\n",
    "- A filtragem garante que apenas a edição FC 24 entra no treino e avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5c48c939be5a7",
   "metadata": {},
   "source": [
    "# Selecionar os dados relevantes\n",
    "\n",
    "### Atribui os grupos de posições baseado na principal posição do jogador. Junta numa coluna nova 'position_group'.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ae9f4aa4439a3a3",
   "metadata": {},
   "source": [
    "def map_position_group(positions_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Mapeia a posição principal do jogador para um grupo simplificado\n",
    "    (GK, DEF, MID, ATT ou OTHER).\n",
    "    \"\"\"\n",
    "    if pd.isna(positions_str):\n",
    "        return \"OTHER\"\n",
    "    main_pos = positions_str.split(\",\")[0].strip()\n",
    "    defenders = {\"CB\", \"LB\", \"RB\", \"LWB\", \"RWB\"}\n",
    "    mids = {\"CDM\", \"CM\", \"CAM\", \"LM\", \"RM\"}\n",
    "    attackers = {\"ST\", \"CF\", \"LW\", \"RW\"}\n",
    "\n",
    "    if main_pos == \"GK\":\n",
    "        return \"GK\"\n",
    "    elif main_pos in defenders:\n",
    "        return \"DEF\"\n",
    "    elif main_pos in mids:\n",
    "        return \"MID\"\n",
    "    elif main_pos in attackers:\n",
    "        return \"ATT\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "# Cria a coluna categórica com os grupos de posição.\n",
    "df_players_fifa24[\"position_group\"] = df_players_fifa24[\"player_positions\"].apply(map_position_group)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73ad021699afc14d",
   "metadata": {},
   "source": [
    "# Seleciona as colunas de atributos que descrevem o jogador.\n",
    "feature_cols = [\n",
    "    \"pace\", \"shooting\", \"passing\", \"dribbling\",\n",
    "    \"defending\", \"physic\",\n",
    "    \"height_cm\", \"weight_kg\", \"age\",\n",
    "    \"movement_acceleration\", \"movement_sprint_speed\",\n",
    "    \"movement_agility\", \"movement_balance\",\n",
    "    \"power_strength\", \"power_stamina\"\n",
    "]\n",
    "\n",
    "# Limpa linhas com valores em falta e separa features (X) e alvo (y).\n",
    "df_training_data = df_players_fifa24.dropna(subset=feature_cols + [\"position_group\"]).copy()\n",
    "\n",
    "feature_matrix = df_training_data[feature_cols]\n",
    "position_labels = df_training_data[\"position_group\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6edc3a5",
   "metadata": {},
   "source": [
    "### Conjunto de features e alvo\n",
    "- `feature_cols`: atributos físicos/técnicos usados como preditores.\n",
    "- `df_training_data`: registros sem valores em falta nas features e na coluna `position_group`.\n",
    "- `feature_matrix` (`X`) e `position_labels` (`y`) são extraídos aqui e usados em todo o fluxo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829d48211f15bee",
   "metadata": {},
   "source": [
    "## Dividir os dados em treino e teste, e escalar as features para melhorar a performance dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5a9b0cc8628d4c5",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Divide os dados mantendo a proporção das classes e normaliza as features numéricas.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_matrix,\n",
    "    position_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=7213,\n",
    "    stratify=position_labels\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c260654d",
   "metadata": {},
   "source": [
    "### Divisão e normalização\n",
    "- `train_test_split` estratificado (80/20) para manter a proporção das classes.\n",
    "- `StandardScaler` ajustado no treino (`X_train`) e aplicado no teste (`X_test`) para evitar vazamento de dados.\n",
    "- As versões escaladas (`X_train_scaled`, `X_test_scaled`) são usadas por todos os modelos seguintes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6df0c9db3aefe5",
   "metadata": {},
   "source": [
    "# Treinar e avaliar vários modelos de classificação\n",
    "\n",
    "Foram utilizados três modelos de classificação: Regressão Logística, Random Forest e K-Nearest Neighbors (KNN). Cada modelo foi treinado com os dados de treino escalados e avaliado com os dados de teste escalados. As métricas de avaliação incluem precisão, recall e F1-score para cada classe"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f5eef08b10355c6",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modelos de base para comparar desempenho.\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=100000),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=6452),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    print(\"====\", name, \"====\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "856a7656",
   "metadata": {},
   "source": [
    "### Avaliação inicial dos modelos\n",
    "- Modelos comparados: Regressão Logística, Random Forest e KNN.\n",
    "- Cada `classification_report` apresenta precisão, recall, F1 por classe e médias macro/micro.\n",
    "- Estes resultados servem como base antes de tunar os hiperparâmetros."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Determinar o melhor modelo e otimizar seus hiperparâmetros com GridSearchCV\n",
    "\n",
    " Com base nos resultados iniciais, o melhor modelo será selecionado e seus hiperparâmetros serão otimizados usando GridSearchCV para tentar melhorar ainda mais o desempenho."
   ],
   "id": "91610bf9dfb2e01e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Otimização com GridSearchCV\n",
    "- O melhor modelo (pelo F1 macro) é reavaliado com grelhas de hiperparâmetros específicas.\n",
    "- `GridSearchCV` usa validação cruzada (`cv=5`) e paraleliza com `n_jobs=-1`.\n",
    "- O relatório final compara o F1 macro original vs. o otimizado para verificar o ganho real."
   ],
   "id": "af7c6516f2f727bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 1. Avaliar e selecionar o melhor modelo inicial com F1 macro.\n",
    "model_scores = {}\n",
    "for name, clf in models.items():\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    model_scores[name] = score\n",
    "    print(f\"F1-Score (macro) para {name}: {score:.4f}\")\n",
    "\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "print(f\"\\nMelhor modelo inicial: {best_model_name} com F1-Score de {model_scores[best_model_name]:.4f}\")\n",
    "\n",
    "# 2. Definir grelhas de parâmetros para cada modelo de forma explícita.\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": [0.1, 1.0, 10.0],\n",
    "        \"solver\": [\"liblinear\", \"saga\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [10, 20, None],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Otimizar o melhor modelo com GridSearchCV usando validação cruzada.\n",
    "best_model_base = models[best_model_name]\n",
    "grid_to_use = param_grids[best_model_name]\n",
    "\n",
    "print(f\"\\nIniciando GridSearchCV para o modelo: {best_model_name}...\")\n",
    "grid = GridSearchCV(\n",
    "    estimator=best_model_base,\n",
    "    param_grid=grid_to_use,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Avaliar o modelo otimizado e comparar com a versão base.\n",
    "print(\"\\nMelhores parâmetros encontrados:\", grid.best_params_)\n",
    "best_model_tuned = grid.best_estimator_\n",
    "y_pred_tuned = best_model_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nRelatório de classificação para o modelo otimizado:\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "print(f\"F1-Score  do modelo original: {f1_score(y_test, models[best_model_name].predict(X_test_scaled), average='macro'):.4f}\")\n",
    "print(f\"F1-Score (macro) do modelo otimizado: {f1_score(y_test, y_pred_tuned, average='macro'):.4f}\")\n"
   ],
   "id": "bccf2fb27ebc7e5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
